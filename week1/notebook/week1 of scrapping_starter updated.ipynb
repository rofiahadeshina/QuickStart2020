{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2OWGGBmGobX"
   },
   "source": [
    "## Web scrapping using python\n",
    "\n",
    "#### References\n",
    "1. [Practical Introduction to Web Scraping in Python](https://realpython.com/python-web-scraping-practical-introduction/)\n",
    "2. [Web Scraping using Python](https://www.datacamp.com/community/tutorials/web-scraping-using-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3978,
     "status": "ok",
     "timestamp": 1595078857054,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "E94qQfZtGobd"
   },
   "outputs": [],
   "source": [
    "# $ python3 -m venv venv\n",
    "# $ . ./venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3962,
     "status": "ok",
     "timestamp": 1595078857065,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "mY-a7L90Gob1"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10471,
     "status": "ok",
     "timestamp": 1595138427433,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "V5IbSjYnGocI",
    "outputId": "6a3aef4f-749e-48e4-a2c2-8c0e86643010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
      "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
      "Collecting fire\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 2.1MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=a27afeb10c33782c86c2f45fd8481a7c079c21b926060ee8803fdd64cab7a417\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
      "Successfully built fire\n",
      "Installing collected packages: fire\n",
      "Successfully installed fire-0.3.1\n"
     ]
    }
   ],
   "source": [
    "#Better\n",
    "#!pip install requests BeautifulSoup4 fire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2433,
     "status": "ok",
     "timestamp": 1595138435582,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "YX2X8cCBGocb"
   },
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "import fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1647,
     "status": "ok",
     "timestamp": 1595138440794,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "E7NxE2cDGocu"
   },
   "outputs": [],
   "source": [
    "#%%writefile ../pyscrap_url.py\n",
    "\n",
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content  #.encode(BeautifulSoup.original_encoding)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)\n",
    "    \n",
    "def get_elements(url, tag='',search={}, fname=None):\n",
    "    \"\"\"\n",
    "    Downloads a page specified by the url parameter\n",
    "    and returns a list of strings, one per tag element\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(url,str):\n",
    "        response = simple_get(url)\n",
    "    else:\n",
    "        #if already it is a loaded html page\n",
    "        response = url\n",
    "\n",
    "    if response is not None:\n",
    "        html = BeautifulSoup(response, 'html.parser')\n",
    "        \n",
    "        res = []\n",
    "        if tag:    \n",
    "            for li in html.select(tag):\n",
    "                for name in li.text.split('\\n'):\n",
    "                    if len(name) > 0:\n",
    "                        res.append(name.strip())\n",
    "                       \n",
    "                \n",
    "        if search:\n",
    "            soup = html            \n",
    "            \n",
    "            \n",
    "            r = ''\n",
    "            if 'find' in search.keys():\n",
    "                print('findaing',search['find'])\n",
    "                soup = soup.find(**search['find'])\n",
    "                r = soup\n",
    "\n",
    "                \n",
    "            if 'find_all' in search.keys():\n",
    "                print('findaing all of',search['find_all'])\n",
    "                r = soup.find_all(**search['find_all'])\n",
    "   \n",
    "            if r:\n",
    "                for x in list(r):\n",
    "                    if len(x) > 0:\n",
    "                        res.extend(x)\n",
    "            \n",
    "        return res\n",
    "\n",
    "    # Raise an exception if we failed to get any data from the url\n",
    "    raise Exception('Error retrieving contents at {}'.format(url))    \n",
    "    \n",
    "    \n",
    "if get_ipython().__class__.__name__ == '__main__':\n",
    "    fire(get_tag_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6597,
     "status": "ok",
     "timestamp": 1595138457218,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "GnXh6DcnGoc8"
   },
   "outputs": [],
   "source": [
    "res = get_elements('https://africafreak.com/100-most-influential-twitter-users-in-africa', tag='h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1468,
     "status": "ok",
     "timestamp": 1595138464846,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "rrIUJ4kPGodc"
   },
   "outputs": [],
   "source": [
    "for i in res[100:]:\n",
    "    res.remove(i)\n",
    "    #print(res)\n",
    "names_infl = []\n",
    "handle_infl = []\n",
    "for r in res:\n",
    "    split_data = r.split('.',maxsplit=1)[1].rsplit('(',maxsplit=1)\n",
    "    name = split_data[0].split(',')[0].strip()\n",
    "    handle =  split_data[1].split(')',maxsplit=1)[0]\n",
    "    names_infl.append(name)\n",
    "    handle_infl.append(handle)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_influencer_handle = pd.DataFrame(handle_infl, columns=[\"100 influencers handles\"])\n",
    "#df_influencer_handle.to_csv('C:/Users/HP/Desktop/CV, P.Statement and others/10 Academy/100_handles.csv', index=False, header=True)\n",
    "#print(df_influencer_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1506,
     "status": "ok",
     "timestamp": 1595138476755,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "V9mULslEGod5"
   },
   "outputs": [],
   "source": [
    "url= 'https://www.atlanticcouncil.org/blogs/africasource/african-leaders-respond-to-coronavirus-on-twitter/#east-africa'\n",
    "response = simple_get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1555,
     "status": "ok",
     "timestamp": 1595138482045,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "mKgUhKcgGoeM",
    "outputId": "2d7d39f6-bf0b-426c-8b6f-a680ddb819bd"
   },
   "outputs": [],
   "source": [
    "url= 'https://www.atlanticcouncil.org/blogs/africasource/african-leaders-respond-to-coronavirus-on-twitter/#east-africa'\n",
    "response = get(url).content\n",
    "re_gov = get_elements(response, tag='blockquote')\n",
    "names = []\n",
    "handles = []\n",
    "for r in re_gov:\n",
    "    split_data = r.split('— ',maxsplit=1)[1].rsplit('(',maxsplit=1)\n",
    "    name = split_data[0].split(',')[0].strip()\n",
    "    handle =  split_data[1].rsplit(')',maxsplit=1)[0]\n",
    "    names.append(name)\n",
    "    handles.append(handle)\n",
    "\n",
    "nam_handle = f'{name}:{handle}'\n",
    "\n",
    "#df_gov_handle = pd.DataFrame(handles, columns=[\"Gov influencers handles\"])\n",
    "#df_gov_handle.to_csv('C:/Users/HP/Desktop/CV, P.Statement and others/10 Academy/gov_handles.csv', index=False, header=True)\n",
    "#print(df_gov_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2383,
     "status": "ok",
     "timestamp": 1595138602555,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "sRsiYQcmGofB",
    "outputId": "e92e6f48-af15-4227-c974-c265be9ed5b7"
   },
   "outputs": [],
   "source": [
    "fl_handles = handles + handle_infl\n",
    "#final_handle = pd.DataFrame(fl_handles, columns=[\"combined_handles\"])\n",
    "#final_handle.to_csv (r'C:\\Users\\HP\\Desktop\\CV, P.Statement and others\\10 Academy\\final_handle.csv', index = False, header=True)\n",
    "#print(final_handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1595138557362,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "fy-VXURDGofc",
    "outputId": "af7ab1c9-c7e9-4ca6-e81c-0d1b5c48991e"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "#sns.set()\n",
    "\n",
    "\n",
    "# to view all columns\n",
    "#pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1380,
     "status": "ok",
     "timestamp": 1595138562340,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "ypAZQeHsGofz"
   },
   "outputs": [],
   "source": [
    "#!pip install tweepy\n",
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1533,
     "status": "ok",
     "timestamp": 1595138568118,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "cDVA2ckbGogA"
   },
   "outputs": [],
   "source": [
    "consumer_key = \"re8a7dLArl8y2Tic312dbRWxH\"\n",
    "consumer_secret = \"DcARRXgLiCfFE0y1aBFF9WlfHtLzZw2TgOCEOkM31rdKG8rJD0\"\n",
    "access_token = \"994261917253472256-bRMXtnLl19sVm2a3flZv6t2WaW9b1AG\"\n",
    "access_token_secret = \"HMnwkCLauS0OLOVNi62Ay1K9OcVlEvgawcfqOSuIIHbJz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1449,
     "status": "ok",
     "timestamp": 1595138573109,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "gnq2TPLeGogQ"
   },
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48619,
     "status": "ok",
     "timestamp": 1595138662559,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "q1E6b1RLGogl",
    "outputId": "3b2ba5dc-577c-46f5-869c-c535cd33a8b9"
   },
   "outputs": [],
   "source": [
    "#getting tweets\n",
    "tweets = []\n",
    "tweetCount=5\n",
    "for i in handle_Infl:\n",
    "    try:\n",
    "        results=api.user_timeline(id=i, count=tweetCount)\n",
    "    except tweepy.TweepError as e:\n",
    "                continue  \n",
    "    for tweet in results:\n",
    "        tweets.append(tweet.text)\n",
    "#print(tweets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23436,
     "status": "ok",
     "timestamp": 1595120085897,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "D3-maCdTGohK",
    "outputId": "b8a79235-29bb-4c40-aa1c-ecc9ad8d1d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11324, 39316, 192482, 126, 1599467, 7171, 546580, 2934, 66256, 1104131, 1984380, 424457, 2560, 371105, 4024, 1813811, 3272, 107412, 18642, 340987, 173617, 30169, 256363, 3283, 832993, 10774, 1508566, 737, 8482, 228970, 31806, 116313, 3272430, 1375833, 14915, 1132]\n",
      "   Number of followers\n",
      "0                11324\n",
      "1                39316\n",
      "2               192482\n",
      "3                  126\n",
      "4              1599467\n"
     ]
    }
   ],
   "source": [
    "# getting followers for 100 influencers\n",
    "# Calling the get_user function with our parameters\n",
    "followers = []\n",
    "for i in handles:\n",
    "    try:\n",
    "        results = api.get_user(id=i)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue \n",
    "    followers.append(results.followers_count)\n",
    "    #print(results.followers_count)\n",
    "print(followers)\n",
    "# followers dataframe\n",
    "total_followers = pd.DataFrame(followers,columns=[\"Number of followers\"])\n",
    "total_followers.to_csv('C:/Users/HP/Desktop/CV, P.Statement and others/10 Academy/gov_follower.csv')\n",
    "print(total_followers.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25705, 31286, 101288, 68073, 21964, 31294, 22798, 8, 50990, 28466, 439432, 52894, 46778, 11927, 24867, 49699, 28444, 117, 17444, 93963, 18239, 21365, 62309, 18499, 19996, 7489, 6, 215386, 232825, 98723, 106165, 70748, 17119, 249964, 48966, 105241, 58232, 80354, 487, 81639, 217261, 192561, 24702, 20448, 191410, 26436, 165773, 1002778, 48253, 50095, 18638, 240621, 105655, 88508, 84533, 1078458, 56242, 127368, 143198, 285565, 131, 215979, 220912, 59207, 29952, 51839, 151981, 114521, 673453, 56876, 541579, 49249, 69, 35228, 938157, 572317, 105683, 183461, 7, 1755568, 1042485, 1160254, 1416120, 200279, 1085295, 1164410, 1060342, 1443391, 3129885, 3578227, 18, 1974635, 10808859]\n",
      "   Number of followers\n",
      "0                25705\n",
      "1                31286\n",
      "2               101288\n",
      "3                68073\n",
      "4                21964\n"
     ]
    }
   ],
   "source": [
    "followers = []\n",
    "for i in handle_infl:\n",
    "    try:\n",
    "        results = api.get_user(id=i)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue \n",
    "    followers.append(results.followers_count)\n",
    "    #print(results.followers_count)\n",
    "print(followers)\n",
    "# followers dataframe\n",
    "totalinf_followers = pd.DataFrame(followers,columns=[\"Number of followers\"])\n",
    "totalinf_followers.to_csv('C:/Users/HP/Desktop/CV, P.Statement and others/10 Academy/infl_follower.csv')\n",
    "print(totalinf_followers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22257,
     "status": "ok",
     "timestamp": 1595117928049,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "KonoEx2wGohn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number of likes\n",
      "0               61\n",
      "1              915\n",
      "2              268\n",
      "3               12\n",
      "4               63\n"
     ]
    }
   ],
   "source": [
    "# getting no of likes for gov influencers\n",
    "likes = []\n",
    "for i in handles:\n",
    "    try:\n",
    "        results = api.get_user(id=i)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "    likes.append(results.favourites_count)\n",
    "    #print(results.followers_count)\n",
    "#print(likes)\n",
    "total_like = pd.DataFrame(likes,columns=[\"Number of likes\"])\n",
    "total_like.to_csv('C:/Users/HP/Desktop/CV, P.Statement and others/10 Academy/gov_likes.csv')\n",
    "print(total_like.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number of likes\n",
      "0               10\n",
      "1             1621\n",
      "2             9027\n",
      "3             3916\n",
      "4             3625\n"
     ]
    }
   ],
   "source": [
    "# getting no of likes for gov influencers\n",
    "likes = []\n",
    "for i in handle_infl:\n",
    "    try:\n",
    "        results = api.get_user(id=i)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "    likes.append(results.favourites_count)\n",
    "    #print(results.followers_count)\n",
    "#print(likes)\n",
    "total_inflike = pd.DataFrame(likes,columns=[\"Number of likes\"])\n",
    "total_inflike.to_csv('C:/Users/HP/Desktop/CV, P.Statement and others/10 Academy/infl_likes.csv')\n",
    "print(total_inflike.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23034,
     "status": "ok",
     "timestamp": 1595120058474,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "WSnc8HF7GoiG",
    "outputId": "e2d87540-7801-4427-9da2-6b0b8fafd31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number of following\n",
      "0                   82\n",
      "1                   26\n",
      "2                   55\n",
      "3                  224\n",
      "4                   14\n"
     ]
    }
   ],
   "source": [
    "# getting no of following for 100 influencers\n",
    "following = []\n",
    "for i in handles:\n",
    "    try:\n",
    "        results = api.get_user(id=i)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "    following.append(results.friends_count)\n",
    "\n",
    "    \n",
    "#print(following)\n",
    "gov_following = pd.DataFrame(following,columns=[\"Number of following\"])\n",
    "gov_following.to_csv('C:/Users/HP/Desktop/CV, P.Statement and others/10 Academy/gov_followings.csv')\n",
    "print(gov_following.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number of following\n",
      "0                   37\n",
      "1                 3059\n",
      "2                 2838\n",
      "3                 4592\n",
      "4                 5050\n"
     ]
    }
   ],
   "source": [
    "# getting no of following for 100 influencers\n",
    "following = []\n",
    "for i in handle_infl:\n",
    "    try:\n",
    "        results = api.get_user(id=i)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "    following.append(results.friends_count)\n",
    "\n",
    "    \n",
    "#print(following)\n",
    "inf_following = pd.DataFrame(following,columns=[\"Number of following\"])\n",
    "inf_following.to_csv('C:/Users/HP/Desktop/CV, P.Statement and others/10 Academy/inf_followings.csv')\n",
    "print(inf_following.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116049,
     "status": "ok",
     "timestamp": 1595117849527,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "GC_jnat2Goiq",
    "outputId": "0f15a951-7513-4803-ecd0-f024c93aae84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No of retweets\n",
      "0              10\n",
      "1              14\n",
      "2              10\n",
      "3              16\n",
      "4               0\n"
     ]
    }
   ],
   "source": [
    "#getting retweets\n",
    "no_of_retweets = []\n",
    "for id in fl_handles:\n",
    "    try:\n",
    "        tweets = tweepy.Cursor(api.user_timeline, id=i).items()\n",
    "        for tweet in tweets:\n",
    "            no_of_retweets.append(tweet.retweet_count)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "#print(no_of_retweets)\n",
    "\n",
    "#retweets dataframe\n",
    "gov_retweets = pd.DataFrame(no_of_retweets, columns=[\"No of retweets\"])\n",
    "gov_retweets.to_csv (r'C:\\Users\\HP\\Desktop\\CV, P.Statement and others\\10 Academy\\gov_retweet.csv', index = False, header=True)\n",
    "print(gov_retweets.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting retweets\n",
    "no_of_retweets = []\n",
    "for id in handle_infl:\n",
    "    try:\n",
    "        tweets = tweepy.Cursor(api.user_timeline, id=i).items()\n",
    "        for tweet in tweets:\n",
    "            no_of_retweets.append(tweet.retweet_count)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "#print(no_of_retweets)\n",
    "\n",
    "#retweets dataframe\n",
    "inf_retweets = pd.DataFrame(no_of_retweets, columns=[\"No of retweets\"])\n",
    "inf_retweets.to_csv (r'C:\\Users\\HP\\Desktop\\CV, P.Statement and others\\10 Academy\\gov_retweet.csv', index = False, header=True)\n",
    "print(inf_retweets.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23123,
     "status": "ok",
     "timestamp": 1595082770029,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "bb2p_vEjGojO",
    "outputId": "1a0435b1-4f8c-4ea9-c24f-e1e9645e0e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1674, 4030, 1087, 125, 18881, 838, 628, 1064, 4718, 9050, 2862, 599, 209, 652, 836, 6644, 732, 40682, 753, 1650, 1738, 5648, 4496, 715, 7139, 1440, 7097, 21, 828, 11168, 30, 349, 4734, 2796, 83, 44, 3771, 16869, 142230, 27324, 19439, 6864, 1638, 1, 21549, 3892, 81200, 16889, 23988, 2166, 2523, 2814, 35262, 23, 4993, 13508, 88730, 42967, 26785, 15627, 9575, 15410, 0, 22994, 7579, 17748, 101293, 4986, 12766, 15755, 8771, 45452, 7187, 35782, 35, 18369, 33459, 14514, 8767, 3906, 48599, 32731, 15884, 265258, 16251, 11100, 8549, 91472, 30378, 23204, 137304, 35966, 10665, 8895, 38395, 53774, 117, 9294, 23704, 13353, 3118, 14758, 3243, 11275, 27250, 14684, 9266, 6476, 1, 21728, 50980, 23582, 27791, 15681, 6, 4525, 19994, 88552, 56044, 45129, 5688, 62840, 144301, 72335, 37213, 322868, 19, 31626, 11186]\n",
      "     No of statuses\n",
      "0              1674\n",
      "1              4030\n",
      "2              1087\n",
      "3               125\n",
      "4             18881\n",
      "5               838\n",
      "6               628\n",
      "7              1064\n",
      "8              4718\n",
      "9              9050\n",
      "10             2862\n",
      "11              599\n",
      "12              209\n",
      "13              652\n",
      "14              836\n",
      "15             6644\n",
      "16              732\n",
      "17            40682\n",
      "18              753\n",
      "19             1650\n",
      "20             1738\n",
      "21             5648\n",
      "22             4496\n",
      "23              715\n",
      "24             7139\n",
      "25             1440\n",
      "26             7097\n",
      "27               21\n",
      "28              828\n",
      "29            11168\n",
      "..              ...\n",
      "99            13353\n",
      "100            3118\n",
      "101           14758\n",
      "102            3243\n",
      "103           11275\n",
      "104           27250\n",
      "105           14684\n",
      "106            9266\n",
      "107            6476\n",
      "108               1\n",
      "109           21728\n",
      "110           50980\n",
      "111           23582\n",
      "112           27791\n",
      "113           15681\n",
      "114               6\n",
      "115            4525\n",
      "116           19994\n",
      "117           88552\n",
      "118           56044\n",
      "119           45129\n",
      "120            5688\n",
      "121           62840\n",
      "122          144301\n",
      "123           72335\n",
      "124           37213\n",
      "125          322868\n",
      "126              19\n",
      "127           31626\n",
      "128           11186\n",
      "\n",
      "[129 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#getting no of tweets shared\n",
    "no_tweets_shared = []\n",
    "for i in handles:\n",
    "    try:\n",
    "        results = api.get_user(id=i)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "    no_tweets_shared.append(results.statuses_count)\n",
    "    \n",
    "print(no_tweets_shared)\n",
    "\n",
    "#tweet shared dataframe\n",
    "gov_statuses = pd.DataFrame(no_tweets_shared, columns=[\"No of statuses\"])\n",
    "gov_statuses.to_csv (r'C:\\Users\\HP\\Desktop\\CV, P.Statement and others\\10 Academy\\gov_statuses.csv', index = False, header=True)\n",
    "print(gov_statuses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting no of tweets shared\n",
    "no_tweets_shared = []\n",
    "for i in handle_infl:\n",
    "    try:\n",
    "        results = api.get_user(id=i)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "    no_tweets_shared.append(results.statuses_count)\n",
    "    \n",
    "#print(no_tweets_shared)\n",
    "\n",
    "#tweet shared dataframe\n",
    "infl_statuses = pd.DataFrame(no_tweets_shared, columns=[\"No of statuses\"])\n",
    "infl_statuses.to_csv (r'C:\\Users\\HP\\Desktop\\CV, P.Statement and others\\10 Academy\\infl_statuses.csv', index = False, header=True)\n",
    "print(infl_statuses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [gov mentions]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#mention for gov influencers\n",
    "count = []\n",
    "for x in range(0, len(handles)):\n",
    "    name = handles[x]\n",
    "    mentions_count = []\n",
    "    try:\n",
    "        for status in tweepy.Cursor(api.user_timeline, id=name).items():\n",
    "            entities = status.entities\n",
    "            if \"user_mentions\" in entities:\n",
    "                for ent in entities[\"user_mentions\"]:\n",
    "                    if ent is not None:\n",
    "                        if \"screen_name\" in ent:\n",
    "                            name = ent[\"screen_name\"]\n",
    "                            if name is not None:\n",
    "                                mentions_count.append(name)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "    count.append(len(mentions_count))\n",
    "    \n",
    "    \n",
    "infl_mention = pd.DataFrame(mentions_count, columns=[\"gov mentions\"])\n",
    "infl_mention.to_csv (r'C:\\Users\\HP\\Desktop\\CV, P.Statement and others\\10 Academy\\infl_statuses.csv', index = False, header=True)\n",
    "print(infl_mention.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mention for top 100 influncers\n",
    "count = []\n",
    "for x in range(0, len(handle_infl)):\n",
    "    name = handle_infl[x]\n",
    "    mentions_count = []\n",
    "    try:\n",
    "       for status in tweepy.Cursor(api.user_timeline, id=name).items():\n",
    "         entities = status.entities\n",
    "         if \"user_mentions\" in entities:\n",
    "            for ent in entities[\"user_mentions\"]:\n",
    "              if ent is not None:\n",
    "                if \"screen_name\" in ent:\n",
    "                  name = ent[\"screen_name\"]\n",
    "                  if name is not None:\n",
    "                    mentions_count.append(name)\n",
    "    except tweepy.TweepError as e:\n",
    "        continue\n",
    "    count.append(len(mentions_count))\n",
    "\n",
    "infl_statuses = pd.DataFrame(no_tweets_shared, columns=[\"No of statuses\"])\n",
    "infl_statuses.to_csv (r'C:\\Users\\HP\\Desktop\\CV, P.Statement and others\\10 Academy\\infl_statuses.csv', index = False, header=True)\n",
    "print(infl_statuses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags(fl_handles):\n",
    "    cols = ['id', 'name', 'screen_name', 'hashtags']\n",
    "    # dataframe that would be returned at the end\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    handle_data = []\n",
    "    if len(fl_handle) > 0: \n",
    "        for handle in fl_handles:\n",
    "            value_list = {}\n",
    "            print(\"Getting hashtags for \" + handle)\n",
    "            # this helps avoid Tweepy errors like suspended users or user not found errors\n",
    "            try:\n",
    "                item = api.get_user(handle)\n",
    "            except tweepy.TweepError as e:\n",
    "                continue\n",
    "            value_list['id'] = item.id_str\n",
    "            value_list['name'] = item.name\n",
    "            value_list['screen_name'] = item.screen_name\n",
    "            #get average daily tweets\n",
    "            no_tweets = item.statuses_count\n",
    "            account_created_date = item.created_at\n",
    "            delta = datetime.utcnow() - account_created_date\n",
    "            account_age_days = delta.days\n",
    "            hashtags = set()\n",
    "            hash_dic = {}\n",
    "            tweet_count = 0\n",
    "            end_date = datetime.utcnow() - timedelta(days=30)\n",
    "            for status in tweepy.Cursor(api.user_timeline, id=twitter_handle).items():\n",
    "                if hasattr(status, \"entities\"):\n",
    "                    entities = status.entities\n",
    "                # get hashtags\n",
    "                if \"hashtags\" in entities:\n",
    "                    for ent in entities[\"hashtags\"]:\n",
    "                        if ent is not None:\n",
    "                            if \"text\" in ent:\n",
    "                                hashtag = ent[\"text\"]\n",
    "                                if hashtag is not None:\n",
    "                                    if hashtag in hashtags:\n",
    "                                        hash_dic[hashtag]+=1\n",
    "                                    else:\n",
    "                                        hashtags.add(hashtag)\n",
    "                                        hash_dic[hashtag] = 1\n",
    "                value_list['hashtags'] = hash_dic\n",
    "            try:\n",
    "                #escape handles with no hashtags\n",
    "                df = df.append(pd.DataFrame(value_list))\n",
    "                # the code snippet below before the return is used to save to file due to constant connections loss\n",
    "                new_df = df.reset_index().rename(columns={'hashtags':'hashtags_count','index':'hashtags'})\n",
    "            except tweepy.TweepError as e:\n",
    "                continue\n",
    "    return df.reset_index().rename(columns={'hashtags':'hashtags_count','index':'hashtags'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMuXtMOQGojk"
   },
   "source": [
    "### Popularity reach\n",
    "### Reach Score\n",
    "### Relevance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1137,
     "status": "ok",
     "timestamp": 1595117945644,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "-2X0qPUlGojn",
    "outputId": "4733dace-c2a5-494f-e209-d951f6350ce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       No of retweets  No of likes  Popularity_score\n",
      "0                 497         61.0             558.0\n",
      "1                2749        915.0            3664.0\n",
      "2               93077        268.0           93345.0\n",
      "3                6013         12.0            6025.0\n",
      "4                1651         63.0            1714.0\n",
      "...               ...          ...               ...\n",
      "14927              73          NaN               NaN\n",
      "14928               3          NaN               NaN\n",
      "14929             670          NaN               NaN\n",
      "14930              70          NaN               NaN\n",
      "14931             112          NaN               NaN\n",
      "\n",
      "[14932 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#popularity reach = retweets + likes\n",
    "popularity = pd.concat([df_retweets,df_likes], axis=1)\n",
    "#print(popularity)\n",
    "popularity[\"Popularity_score\"] = popularity[\"No of retweets\"]+popularity[\"No of likes\"]\n",
    "print(popularity)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1595120099637,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "ccyr9H0DGokI",
    "outputId": "9f995434-8f2f-402f-c372-002fab8ad9fa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_followers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-56a06924e186>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Reach Score = followers - following\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreach\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_fl_handles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_followers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_following\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreach\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reach_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mreach\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Number of followers\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mreach\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Number of following\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_followers' is not defined"
     ]
    }
   ],
   "source": [
    "#Reach Score = followers - following\n",
    "reach = pd.concat([df_fl_handles,df_followers,d_following], axis=1)\n",
    "print(reach.head())\n",
    "reach['reach_score']= reach[\"Number of followers\"] - reach[\"Number of following\"]\n",
    "print(reach.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZcjqFvPZzcG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3235,
     "status": "aborted",
     "timestamp": 1595078857263,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "-QKPJXRGGome"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBmhnfEwGomw"
   },
   "source": [
    "## Web scrapping using bash script\n",
    "If the web site has a quite simple HTML, you can easily use curl to perform the request and then extract the needed values using bash commands grep, cut , sed, ..\n",
    "\n",
    "This tutorial is adapted from [this](https://medium.com/@LiliSousa/web-scraping-with-bash-690e4ee7f98d) medium article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3228,
     "status": "aborted",
     "timestamp": 1595078857267,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "yL53kh9wGomy"
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# curl the page and save content to tmp_file\n",
    "#url = \"https://www.atlanticcouncil.org/blogs/africasource/african-leaders-respond-to-coronavirus-on-twitter/#east-africa\"\n",
    "#curl -X GET $url -o tmp_file\n",
    "\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# write headers to CSV file\n",
    "echo \"Name, twitter_id\" >> extractData.csv\n",
    "n=\"1\"\n",
    "while [ $n -lt 2 ]\n",
    "do\n",
    "  \n",
    "  #get title\n",
    "  title=$(cat tmp_file | grep \"class=\\\"twitter-tweet\\\"\" | cut -d ';' -f1 )\n",
    "  echo $title\n",
    "  #get author\n",
    "  #twitter_id=$(cat tmp_file |grep -A1 \"class=\\\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\\\"\" | tail -1)\n",
    "\n",
    "  #echo \"$title, $twitter_id\" >> extractData.csv\n",
    "  #echo \"$title, $twitter_id\"\n",
    "    \n",
    "  n=$[$n+1]\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3221,
     "status": "aborted",
     "timestamp": 1595078857270,
     "user": {
      "displayName": "Rofiah Adeshina",
      "photoUrl": "",
      "userId": "16819728728819546989"
     },
     "user_tz": -60
    },
    "id": "BcuIP_IXGom8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of scrapping_starter updated.ipynb",
   "provenance": [
    {
     "file_id": "1-FjCJfNIAmr7Jck4jue0pKjBu4cGKwRf",
     "timestamp": 1595139295073
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
